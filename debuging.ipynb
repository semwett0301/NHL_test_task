{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PVS9dRcpYTP2"},"outputs":[],"source":["import csv\n","import numpy as np\n","from typing import Set,Tuple, List\n","import torch\n","import torch.utils\n","import torch.utils.data\n","import torch.nn as nn\n","import torchvision\n","NoneType = type(None)\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output\n","from PIL import Image\n","import torchvision.transforms.functional as TF\n","from torchvision.models import vgg11\n","from torchvision.models import mobilenet_v2\n","import torchvision.transforms as transforms\n","import time\n"]},{"cell_type":"markdown","metadata":{"id":"nqnff1WDYTP3"},"source":["<h1 id=\"exercise-1\"><strong>Exercise 1</strong></h1>\n"]},{"cell_type":"markdown","metadata":{"id":"uAvjoS5QYTP3"},"source":["<font size=\"4px\"><p>This method returns the fruit name by getting the string at a specific index of the set.</p>\n","<dl>\n","<dt>param fruit_id</dt>\n","<dd><p>The id of the fruit to get</p>\n","</dd>\n","<dt>param fruits</dt>\n","<dd><p>The set of fruits to choose the id from</p>\n","</dd>\n","<dt>return</dt>\n","<dd><p>The string corrosponding to the index <code>fruit_id</code></p>\n","</dd>\n","</dl>\n","<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n","<div class=\"line-block\"><code>1   It does not print the fruit at the correct index, why is the returned result wrong?</code><br />\n","<code>2   How could this be fixed?</code></div>\n","<p>This example demonstrates the issue: name1, name3 and name4 are expected to correspond to the strings at the indices 1, 3, and 4: 'orange', 'kiwi' and 'strawberry'..</p>\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06DAB_YLYTP4"},"outputs":[],"source":["# You can copy this code to your personal pipeline project or execute it here.\n","def id_to_fruit(fruit_id: int, fruits: list[str]) -> str:\n","    \"\"\"\n","    This method returns the fruit name by getting the string at a specific index of the set.\n","\n","    :param fruit_id: The id of the fruit to get\n","    :param fruits: The set of fruits to choose the id from\n","    :return: The string corrosponding to the index ``fruit_id``\n","\n","    **This method is part of a series of debugging exercises.**\n","    **Each Python method of this series contains bug that needs to be found.**\n","\n","    | ``1   It does not print the fruit at the correct index, why is the returned result wrong?``\n","    | ``2   How could this be fixed?``\n","\n","    This example demonstrates the issue:\n","    name1, name3 and name4 are expected to correspond to the strings at the indices 1, 3, and 4:\n","    'orange', 'kiwi' and 'strawberry'..\n","\n","    >>> name1 = id_to_fruit(1, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n","    >>> name3 = id_to_fruit(3, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n","    >>> name4 = id_to_fruit(4, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n","    \"\"\"\n","    if fruit_id > len(fruits):\n","      raise RuntimeError(f\"Fruit with id {fruit_id} does not exist\")\n","\n","    return fruits[fruit_id]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714739330501,"user":{"displayName":"Emre Nitaelğe","userId":"08740141434959759821"},"user_tz":-180},"id":"losoZ5yLYTP4","outputId":"9c4c7189-2d69-47ff-f48d-8beb9d702241"},"outputs":[{"name":"stdout","output_type":"stream","text":["orange\n","kiwi\n","strawberry\n"]}],"source":["name1 = id_to_fruit(1, [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"])\n","name3 = id_to_fruit(3, [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"])\n","name4 = id_to_fruit(4, [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"])\n","\n","print(name1)\n","print(name3)\n","print(name4)\n"]},{"cell_type":"markdown","metadata":{"id":"nYaLpcBhbeGA"},"source":["It is not correct to use Set here, because bussines logic requires obtaining a fruit by its index, but set is unordered data structure in Python\n"]},{"cell_type":"markdown","metadata":{"id":"7VVKxW6CYTP4"},"source":["<h1 id=\"exercise-2\"><strong>Exercise 2</strong></h1>\n"]},{"cell_type":"markdown","metadata":{"id":"88E_iCs9YTP4"},"source":["<font size=\"4px\"><p>This method will flip the x and y coordinates in the coords array.</p>\n","<dl>\n","<dt>param coords</dt>\n","<dd><p>A numpy array of bounding box coordinates with shape [n,5] in format: :</p>\n","<pre><code>[[x11, y11, x12, y12, classid1],\n"," [x21, y21, x22, y22, classid2],\n"," ...\n"," [xn1, yn1, xn2, yn2, classid3]]</code></pre>\n","</dd>\n","<dt>return</dt>\n","<dd><p>The new numpy array where the x and y coordinates are flipped.</p>\n","</dd>\n","</dl>\n","<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n","<div class=\"line-block\"><code>1   Can you spot the obvious error?</code><br />\n","<code>2   After fixing the obvious error it is still wrong, how can this be fixed?</code></div>\n","</font>"]},{"cell_type":"markdown","metadata":{"id":"U2H7fWBeYTP4"},"source":["<font size=\"4px\"><p>The example demonstrates the issue. The returned swapped_coords are expected to have swapped x and y coordinates in each of the rows.</p>\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIoJPYg8YTP4"},"outputs":[],"source":["# You can copy this code to your personal pipeline project or execute it here.\n","def swap(coords: np.ndarray):\n","    \"\"\"\n","    This method will flip the x and y coordinates in the coords array.\n","\n","    :param coords: A numpy array of bounding box coordinates with shape [n,5] in format:\n","        ::\n","\n","            [[x11, y11, x12, y12, classid1],\n","             [x21, y21, x22, y22, classid2],\n","             ...\n","             [xn1, yn1, xn2, yn2, classid3]]\n","\n","    :return: The new numpy array where the x and y coordinates are flipped.\n","\n","    **This method is part of a series of debugging exercises.**\n","    **Each Python method of this series contains bug that needs to be found.**\n","\n","    | ``1   Can you spot the obvious error?``\n","    | ``2   After fixing the obvious error it is still wrong, how can this be fixed?``\n","\n","    >>> import numpy as np\n","    >>> coords = np.array([[10, 5, 15, 6, 0],\n","    ...                    [11, 3, 13, 6, 0],\n","    ...                    [5, 3, 13, 6, 1],\n","    ...                    [4, 4, 13, 6, 1],\n","    ...                    [6, 5, 13, 16, 1]])\n","    >>> swapped_coords = swap(coords)\n","\n","    The example demonstrates the issue. The returned swapped_coords are expected to have swapped\n","    x and y coordinates in each of the rows.\n","    \"\"\"\n","\n","    return coords.swapaxes(0,1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1714739853324,"user":{"displayName":"Emre Nitaelğe","userId":"08740141434959759821"},"user_tz":-180},"id":"KW-8ZhL7YTP4","outputId":"fb608441-8052-4166-9c5e-d222dde7849f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[10 11  5  4  6]\n"," [ 5  3  3  4  5]\n"," [15 13 13 13 13]\n"," [ 6  6  6  6 16]\n"," [ 0  0  1  1  1]]\n"]}],"source":["import numpy as np\n","coords = np.array([[10, 5, 15, 6, 0],\n","                   [11, 3, 13, 6, 0],\n","                   [5, 3, 13, 6, 1],\n","                   [4, 4, 13, 6, 1],\n","                   [6, 5, 13, 16, 1]])\n","swapped_coords = swap(coords)\n","print(swapped_coords)\n"]},{"cell_type":"markdown","metadata":{"id":"oQp5ahYbe0K1"},"source":["To be honest with you, I really didn't get what the author wanted to say by this code. In my opinion, the major problem is that he haven't used NumPy for the purpose that already implemented there. I'd even probably abandon the function, but it depends on the project."]},{"cell_type":"markdown","metadata":{"id":"z4SuBSpIYTP5"},"source":["<h1 id=\"exercise-3\"><strong>Exercise 3</strong></h1>\n"]},{"cell_type":"markdown","metadata":{"id":"Mk-XVRUzYTP5"},"source":["<font size=\"4px\"><p>This code plots the precision-recall curve based on data from a .csv file, where precision is on the x-axis and recall is on the y-axis. It it not so important right now what precision and recall means.</p>\n","<dl>\n","<dt>param csv_file_path</dt>\n","<dd><p>The CSV file containing the data to plot.</p>\n","</dd>\n","</dl>\n","<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n","<div class=\"line-block\"><code>1   For some reason the plot is not showing correctly, can you find out what is going wrong?</code><br />\n","<code>2   How could this be fixed?</code></div>\n","<p>This example demonstrates the issue. It first generates some data in a csv file format and the plots it using the <code>plot_data</code> method. If you manually check the coordinates and then check the plot, they do not correspond.</p>\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bv-l0wWgYTP5"},"outputs":[],"source":["# You can copy this code to your personal pipeline project or execute it here.\n","def plot_data(csv_file_path: str):\n","    \"\"\"\n","    This code plots the precision-recall curve based on data from a .csv file,\n","    where precision is on the x-axis and recall is on the y-axis.\n","    It it not so important right now what precision and recall means.\n","\n","    :param csv_file_path: The CSV file containing the data to plot.\n","\n","\n","    **This method is part of a series of debugging exercises.**\n","    **Each Python method of this series contains bug that needs to be found.**\n","\n","    | ``1   For some reason the plot is not showing correctly, can you find out what is going wrong?``\n","    | ``2   How could this be fixed?``\n","\n","    This example demonstrates the issue.\n","    It first generates some data in a csv file format and the plots it using the ``plot_data`` method.\n","    If you manually check the coordinates and then check the plot, they do not correspond.\n","\n","    >>> f = open(\"data_file.csv\", \"w\")\n","    >>> w = csv.writer(f)\n","    >>> _ = w.writerow([\"precision\", \"recall\"])\n","    >>> w.writerows([[0.013,0.951],\n","    ...              [0.376,0.851],\n","    ...              [0.441,0.839],\n","    ...              [0.570,0.758],\n","    ...              [0.635,0.674],\n","    ...              [0.721,0.604],\n","    ...              [0.837,0.531],\n","    ...              [0.860,0.453],\n","    ...              [0.962,0.348],\n","    ...              [0.982,0.273],\n","    ...              [1.0,0.0]])\n","    >>> f.close()\n","    >>> plot_data('data_file.csv')\n","    \"\"\"\n","    # load data\n","    results = []\n","    with open(csv_file_path) as result_csv:\n","        csv_reader = csv.reader(result_csv, delimiter=',')\n","        next(csv_reader)\n","        for row in csv_reader:\n","            results.append(row)\n","        results = np.stack(results)\n","\n","    # plot precision-recall curve\n","    x_values = [float(x) for x in results[:, 0]]\n","    y_values = [float(y) for y in results[:, 1]]\n","\n","    plt.plot(x_values, y_values)\n","    plt.ylim([-0.05, 1.05])\n","    plt.xlim([-0.05, 1.05])\n","    plt.xlabel('Precision')\n","    plt.ylabel('Recall')\n","    plt.xticks(np.arange(min(x_values), max(x_values)+1, 1.0))\n","    plt.xticks(0.05)\n","    plt.grid ( True )\n","    plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":753},"executionInfo":{"elapsed":4,"status":"error","timestamp":1714742340580,"user":{"displayName":"Emre Nitaelğe","userId":"08740141434959759821"},"user_tz":-180},"id":"VxQxa77qYTP5","outputId":"797d45aa-887a-42c6-f82e-1ac1ad6489e0"},"outputs":[{"ename":"ValueError","evalue":"0.05 is not a valid value for scale; supported values are 'linear', 'log', 'symlog', 'asinh', 'logit', 'function', 'functionlog'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-91ef2e4b33c9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m              [1.0,0.0]])\n\u001b[1;32m     15\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-48-582e417d6b91>\u001b[0m in \u001b[0;36mplot_data\u001b[0;34m(csv_file_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36myscale\u001b[0;34m(value, **kwargs)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3113\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_axes_scale\u001b[0;34m(self, value, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axis_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_scale\u001b[0;34m(self, value, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScaleBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/scale.py\u001b[0m in \u001b[0;36mscale_factory\u001b[0;34m(scale, axis, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0mscale_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_scale_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscale_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36mcheck_getitem\u001b[0;34m(_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;34m\"{!r} is not a valid value for {}; supported values are {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             .format(v, k, ', '.join(map(repr, mapping)))) from None\n","\u001b[0;31mValueError\u001b[0m: 0.05 is not a valid value for scale; supported values are 'linear', 'log', 'symlog', 'asinh', 'logit', 'function', 'functionlog'"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjoAAAGwCAYAAACgi8/jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBU0lEQVR4nO3deXiU5d328XMmyWTPQBLIRiBsshN2iOyagkpR2kfBpWUpYuVBq2JbxbcVn7rgUii1ICgKaN0QaykVxGIUBAmiQFjUsEMCIRsxO1ln3j9CBlMCTkKSezL5fo5jjjZ3rvue32DrnFyryW632wUAAOCGzEYXAAAA0FgIOgAAwG0RdAAAgNsi6AAAALdF0AEAAG6LoAMAANwWQQcAALgtT6MLaGo2m01paWkKDAyUyWQyuhwAAOAEu92ugoICRUZGymx2vp+mxQWdtLQ0RUdHG10GAACoh9TUVLVr187p9i0u6AQGBkqq+oMKCgoyuBoAAOCM/Px8RUdHO77HndXigk71cFVQUBBBBwCAZqau006YjAwAANwWQQcAALgtgg4AAHBbBB0AAOC2CDoAAMBtEXQAAIDbIugAAAC3RdABAABui6ADAADcFkEHAAC4LUODzueff66JEycqMjJSJpNJ69at+9F7tmzZogEDBsjb21tdunTR6tWrG71OAADQPBkadIqKihQbG6ulS5c61f7EiROaMGGCxo4dq6SkJD344IO6++679fHHHzdypQAAoDky9FDPG2+8UTfeeKPT7ZcvX66OHTtq4cKFkqQePXpo+/bt+stf/qLx48c3VpkAAKCZalZzdBITExUfH1/j2vjx45WYmHjZe0pLS5Wfn1/jBQAAWoZmFXTS09MVFhZW41pYWJjy8/N1/vz5Wu9ZsGCBrFar4xUdHd0UpQIAABfQrIJOfcybN095eXmOV2pqqtElAQCAJmLoHJ26Cg8PV0ZGRo1rGRkZCgoKkq+vb633eHt7y9vbuynKAwAALqZZ9ejExcUpISGhxrXNmzcrLi7OoIoAAIArMzToFBYWKikpSUlJSZKqlo8nJSUpJSVFUtWw09SpUx3t7733Xh0/fly///3vlZycrJdeeknvvfeeHnroISPKBwAALs7QoPP111+rf//+6t+/vyRp7ty56t+/vx5//HFJ0tmzZx2hR5I6duyoDRs2aPPmzYqNjdXChQv16quvsrQcAADUymS32+1GF9GU8vPzZbValZeXp6CgIKPLAQAATqjv93ezmqMDAABQFwQdAADgtgg6AADAbRF0AACA2yLoAAAAt0XQAQAAbougAwAA3BZBBwAAuK1mdahnc/Td2Xwt+ChZse2s6hNlVWx0K4UF+RhdFgAALQJBp5HtSflenx/O0ueHsxzX2gZ6q2+7Vurbznrh1UrB/hYDqwQAwD1xBEQjSzlXrK1HsnTgdK72n87T4YwC2Wr5E2/X2lex7Vqpz4Xw0zvKqiAfr0avDwCA5qC+398EnSZ2vqxS36Tlaf/pPO2/EH6OZxfV2rZTG3/1jarq8YmNtqpnhFW+Fo8mrhgAAOMRdJxkdNCpTX5JuQ6eztP+MxfDz+nvz1/SzsNsUte2AY7hrr7trOoeHiSLJ3PKAQDujaDjJFcMOrU5V1iqA2cu9vzsO52nrILSS9pZPMzqHhFYI/x0aRMgTw/CDwDAfRB0nNRcgk5t0vNKHD0+1b0/ucXll7Tz9fJQr8igGhOeY0L8ZTabDKgaAICrR9BxUnMOOv/Nbrfr9Pfnta86/JzO1cEz+SosrbikbaCPp/pEWdWnnbVq0nOUVe1a+8pkIvwAAFwfQcdJ7hR0amOz2XU8u+hiz8/pXH2Tlq/SCtslbYP9LVU9PlEXh73asscPAMAFEXSc5O5BpzYVlTYdziisCj8XhrySzxaoopZ17uFBPhd6fazq066V+kZZ1Zo9fgAABiPoOKklBp3alJRXKjm9QAcuTHQ+cDpPRzJr3+OnfbDfxfATVbXXT4A3e00CAJoOQcdJBJ3LKyqt0Ldn87UvtWrY68CZPJ2oZY8fk0nqFOr/gw0OW6lXZJB8vNjjBwDQOAg6TiLo1E1ecbkOpuVp3+lcHThdtdz9TG7te/xcExZ4YcirasLzNWGB7PEDAGgQBB0nEXSuXnZhqSP0VO/xk11Yyx4/nmb1iAi6MNm56kDTzm0C5MEydwBAHRF0nETQaXh2u13p+SXal5qnA2eqV3vlKe/8pXv8+Fk81DvS6jjTq2+7VooJ8WOZOwDgigg6TiLoNA273a6UnOIavT7fnMlTUVnlJW2DfDwdc336RlnVN7qVIq0+hB8AgANBx0kEHeNU2uw6nlV48UDTM3n6Ji1fZbXs8RMaYFGfH+zv07ddK7UJ9DagagCAKyDoOImg41rKK206nFFQ4zT3Q+m17/ETYfWpcaZXnyirWvmxxw8AtAQEHScRdFxfSXmlvjub75jrs/90ro5mFaq2/6V2CPG7OOTVzqpeUezxAwDuiKDjJIJO81RUWqGD1ae5X9jd+dS54kvamUxSlzYBF8/0amdVzwj2+AGA5o6g4ySCjvvILS7TgTMXe30OnM5TWl7JJe08zSZ1Cw90DHv1ibKqW3igvDzY4wcAmguCjpMIOu4ts6Ckxh4/+0/n6VxR2SXtLJ5m9YwIcpzpFdvOqk7s8QMALoug4ySCTstit9uVlldS40yv/adzlV9ScUlbf4uHekVZHUvcY9tZ1T6YPX4AwBUQdJxE0IHdbtfJc8WOHp8Dp/N0MC1PxbXs8WP19XKs8Kpe7RXBHj8A0OQIOk4i6KA2lTa7jmUVal9qrg6cydO+03n6Li1fZZW17fHjfWG+z8UJz6EB7PEDAI2JoOMkgg6cVVZRtcdP9YGm+07n6XBGgSpr2eMnqpVvVa9PtFV9o6rCj9XXy4CqAcA9EXScRNDB1Sgpr9Q3afk6cGHYa9/pXB3PLqp1j5+Y6j1+Lqz26h0VJD8Le/wAQH0QdJxE0EFDKygp18Ez+Tpw5uKE55ScS/f4MZukLm0DaoSf7uGB7PEDAE4g6DiJoIOm8H1R9R4/F8NPev6le/x4eVTv8VO9u3MrdQ0LYI8fAPgvBB0nEXRglMz8khoHmu4/naecWvb48fY0q1dk0A96fqzqFBogM3v8AGjBCDpOIujAVdjtdp3JPV/jTK8Dp/NUUHrpHj8B3p7qFRmk2OiqnZ1j27VSdLAvy9wBtBgEHScRdODKbDa7Tp4rqhF+DqblqaT80mXurfy8HKGn+myvsCBvwg8At0TQcRJBB81NRaVNR7MKa/T6fHe2oNY9ftoEelcdaxHV6sJSd6tC2OMHgBsg6DiJoAN3UFpRqUPpBTXO9DqSWXjZPX5io6vCT2w7q3pFsccPgOaHoOMkgg7c1fmySn17Nk/7UvMu7O6cq+NZRbW2DfG3qH2In2JC/NU+2E8dQqpe7YP9FRpgYfgLgMsh6DiJoIOWJL+kXAcvrPA6cGGDw9Pfn7/iPf4WD7UP8VeHCwHoh4EospUvJ7wDMARBx0kEHbR0BSXlOnWuWCk5xTp5rkgp54odP6flna91l+dqXh4mtWvtp/bBfooJ8asRiKKD/dj8EECjIeg4iaADXF5pRaVSc84rJadIpy4EoFPninQqp1inc87XOgH6hyKsPj8YCvOv+s9gf7UP8WNeEICrQtBxEkEHqJ9Km13p+SU6lV0VfKp6gS4GosJa9v/5oaEdgzV7TGeNvqYNc4AA1BlBx0kEHaDh2e125RSV6VROsWMorLon6NS5YmUXljra9ogI0uwxnXVT73B5ctQFACcRdJxE0AGaXlruea3cfkJv70pRcVmlJKl9sJ/uGdVJtw5sx9weAD+KoOMkgg5gnNziMr2ReEqrvjih74vLJUmhARbNGN5RvxjWgXk8AC6LoOMkgg5gvOKyCr33VapWbDuhM7lVy90DvD1119D2+tWIjgoL8jG4QgCuhqDjJIIO4DrKK236cH+alm05psMZhZIki4dZ/zMwSveM6qyOof4GVwjAVRB0nETQAVyPzWbXZ4cytWzLMX196ntJkskk3dQ7QveO7qw+7awGVwjAaAQdJxF0ANf21ckcLd9yTAnJmY5rI7qEavaYzrq2cwhL04EWiqDjJIIO0Dwkp+fr5a3HtX5fmuOw0r7trJo9urPG9QrnKAqghSHoOImgAzQvqTnFenXbca35OlUl5VU7M3cM9devR3XSzwZEyduTpelAS0DQcRJBB2iezhWW6vUdJ/V64inlna9amt420Ft3j+yoO4a0V6APS9MBd1bf72/DtyVdunSpYmJi5OPjo6FDh2rXrl1XbL948WJ169ZNvr6+io6O1kMPPaSSkpImqhaAUUICvDV3XDd98eh1+sOEHgoP8lFmQame2Zis4c9+qhc+Tq6xAzMASAb36KxZs0ZTp07V8uXLNXToUC1evFhr167VoUOH1LZt20vav/322/rVr36llStX6tprr9Xhw4c1ffp03X777Vq0aJFT70mPDuAeyipsWpd0Rsu3HtPxrCJJkrenWZMHRWvWyE5qH+JncIUAGlKzHLoaOnSoBg8erCVLlkiSbDaboqOjdf/99+vRRx+9pP19992n7777TgkJCY5rDz/8sL788ktt37691vcoLS1VaenFv+Xl5+crOjqaoAO4CZvNrv98m6FlW49pX2quJMlskn7aN1L3ju6snpH8/xxwB81u6KqsrEy7d+9WfHz8xWLMZsXHxysxMbHWe6699lrt3r3bMbx1/Phxbdy4UTfddNNl32fBggWyWq2OV3R0dMN+EACGMptNuqF3uNb977V6Z9YwjbqmjWx2af2+NN304jZNX7VLXx4/pxY2HRHABZ5GvXF2drYqKysVFhZW43pYWJiSk5NrvefOO+9Udna2RowYIbvdroqKCt1777167LHHLvs+8+bN09y5cx0/V/foAHAvJpNJcZ1DFNc5RAfP5Gn51mPaeOCsthzK0pZDWerfvpVmj+6s+B5hMrM0HWgxDJ+MXBdbtmzRM888o5deekl79uzRBx98oA0bNujJJ5+87D3e3t4KCgqq8QLg3npHWbXkzgH67LdjdNfQ9rJ4mrU3JVf3/H23xi3+XO/vPq2yCpvRZQJoAobN0SkrK5Ofn5/ef/99TZo0yXF92rRpys3N1b/+9a9L7hk5cqSGDRumF154wXHtzTff1D333KPCwkKZzT+e25iMDLQ8mQUlWvXFSb2ZeEoFpRWSpEirj2aO7KTbB0fL39uwzm0ATmp2c3QsFosGDhxYY2KxzWZTQkKC4uLiar2nuLj4kjDj4VG1WRjj7wAup22gjx65obu+mHedHr2xu9oEeistr0RPfvithj/3qf6y+bByisqMLhNAIzD0rzFz587VtGnTNGjQIA0ZMkSLFy9WUVGRZsyYIUmaOnWqoqKitGDBAknSxIkTtWjRIvXv319Dhw7V0aNH9cc//lETJ050BB4AuJwgHy/dO7qzpl8bow/2nNHLnx/TqXPF+mvCEb3y+XHdPiRad4/spKhWvkaXCqCBGBp0pkyZoqysLD3++ONKT09Xv379tGnTJscE5ZSUlBo9OH/4wx9kMpn0hz/8QWfOnFGbNm00ceJEPf3000Z9BADNkI+Xh+4c2l5TBkfro4NntWzLMX2Tlq9VX5zU3xNP6eZ+VUvTrwkLNLpUAFeJIyAAtHh2u13bj2Zr2ZZj2nHsnON6fI+2mj2mswZ2CDawOgBSM90w0AgEHQBXkpSaq+Vbjunjb9NV/W/HITHBmj2ms8Z0ayOTiaXpgBEIOk4i6ABwxrGsQr2y9bg+2Hta5ZVV/5rsHh6o2WM6a0KfCHl6NKvdOYBmj6DjJIIOgLpIzyvRa9uP6+0vU1RUVilJatfaV/eM6qTbBkbL18JCCKApEHScRNABUB+5xWX6e+Iprd5xUucuLEUP8bdoxvAY/XJYjKx+XgZXCLg3go6TCDoArsb5skqt3Z2qVz4/rtPfn5ck+VuqVnHNHNFJ4VYfgysE3BNBx0kEHQANoaLSpg0HqpamJ6cXSJK8PEy6e2Qn/W5cN87TAhoYQcdJBB0ADclut2vLoSwt23JMu07mSJKmDIrWMz/vIw/CDtBgmt0READgDkwmk8Z2b6v37o3Tn2+Lldkkrfk6VQ+/l6SKSg4OBYxG0AGABnLrwHb62x0D5Gk2aV1Smu5/Zy+npAMGI+gAQAOa0DdCy34xUBYPsz46mK5739ytkvJKo8sCWiyCDgA0sJ/0DNOr0wbJx8usT5MzdffrX6u4rMLosoAWiaADAI1g1DVttHrGEPlZPLT9aLamr/xKBSXlRpcFtDgEHQBoJMM6hejvM4cq0MdTu07m6Bev7VJeMWEHaEoEHQBoRAM7tNY7s4aptZ+X9qXm6o4VO3WusNTosoAWg6ADAI2sd5RV794Tp9AAb317Nl+3v7JTmfklRpcFtAgEHQBoAt3CA7Xm18MUHuSjI5mFmvLKTqXlnje6LMDtEXQAoIl0bhOg934dp3atfXUiu0iTX05Uyrlio8sC3BpBBwCaUPsQP7336zjFhPjp9PfnNfnlRB3LKjS6LMBtEXQAoIlFtvLVe7+OU9e2AUrPL9GUlxOVnJ5vdFmAWyLoAIAB2gb56N17hqlnRJCyC8t0+ys7dfBMntFlAW6HoAMABgkJ8NY7s4YpNrqVcovLdceKndqT8r3RZQFuhaADAAay+nnpzZlDNCQmWAUlFfrlq19q5/FzRpcFuA2CDgAYLNDHS6t/NVgjuoSqqKxS01ft0ueHs4wuC3ALBB0AcAF+Fk+9Om2QruveViXlNt39+tf65NsMo8sCmj2CDgC4CB8vDy3/xUDd2DtcZZU23fvmbm3Yf9bosoBmjaADAC7E4mnW3+7or0n9IlVhs+v+d/bogz2njS4LaLYIOgDgYjw9zFo4uZ+mDIqWzS49vHaf3tmVYnRZQLNE0AEAF+RhNmnBz/toWlwH2e3SvA8OaNUXJ4wuC2h2CDoA4KLMZpOeuLmXfj2qkyTp//79rZZtOWZwVUDzQtABABdmMpn06I3d9cD1XSVJz21K1qLNh2W32w2uDGgeCDoA4OJMJpMe+sk1euSG7pKkFxOO6NmPkgk7gBMIOgDQTMwe01lPTOwpSXr58+N6Yv03stkIO8CVEHQAoBmZPryjFvy8j0wm6fXEU3rsnwdUSdgBLougAwDNzB1D2mvR5FiZTdK7X6XqoTVJKiytMLoswCURdACgGfpZ/3ZacucAeZpNWr8vTdcv3KIP96cxbwf4LwQdAGimbuoToTd+NUQdQvyUkV+q+97eq6krd+l4VqHRpQEug6ADAM3YtV1C9fGDo/RgfFdZPM3adiRbNyzepj9/fEjnyyqNLg8wHEEHAJo5Hy8PPRh/jTY/NEpju7VRWaVNSz47qp/8Zas2cwI6WjiCDgC4iQ4h/lo5fbCW/2KgIq0+Ov39ec1642vNXP2VUnOKjS4PMARBBwDciMlk0g29w/XJw6M1e0xneXmYlJCcqfhFW/W3hCMqrWA4Cy0LQQcA3JCfxVOP3NBdHz0wUnGdQlRaYdPCzYd1w+Jt+vxwltHlAU2GoAMAbqxL20C9PWuo/np7P7UJ9NaJ7CJNXblLc97ao7N5540uD2h0BB0AcHMmk0m39ItSwsOjNWN4jMwmacOBs7p+4Va98vkxlVfajC4RaDQmewvbXSo/P19Wq1V5eXkKCgoyuhwAaHLfpuXrj/86qN2nvpckXRMWoCdv6a2hnUIMrgy4vPp+f9OjAwAtTM/IIK39dZyev7Wvgv0tOpxRqCmv7NTcNUnKKig1ujygQRF0AKAFMptNmjwoWp8+PFp3Dm0vk0n6YO8ZXbdwi95IPMlBoXAbDF0BALQvNVd/WHdQB87kSZJ6RwXpyVt6q3/71gZXBlSp7/c3QQcAIEmqtNn19q4UvbApWfklFTKZpNsHR+v347urtb/F6PLQwjFHBwBwVTzMJv1yWAd9+tsx+p8B7WS3S+/sStV1C7dozVcpsjGchWaIHh0AQK12ncjRH9cd1KGMAknSgPat9OSk3uoVaTW4MrREDF05iaADAM4rr7Tp9R0n9ZfNh1VUVimzSZoaF6O5465RkI+X0eWhBWHoCgDQ4Lw8zLp7ZCclPDxGP+0bIZtdWr3jpK5fuFXr9p5RC/u7MpohenQAAE7bfiRbj//roI5nF0mShnUK1pO39FbXsECDK4O7o0cHANDoRnQN1UcPjtTvxneTj5dZO4/n6Ma/btOCj75TUWmF0eUBlyDoAADqxNvTQ3PGdtHmh0YrvkeYKmx2vbz1uH6yaKs+OnCW4Sy4FIIOAKBeooP99Oq0QXp16iC1a+2rtLwSzX5rj6av+konLwxtAUYzPOgsXbpUMTEx8vHx0dChQ7Vr164rts/NzdWcOXMUEREhb29vXXPNNdq4cWMTVQsA+G/xPcO0+aHRuv+6LrJ4mLX1cJbGLf5cizYfVkl5pdHloYUzNOisWbNGc+fO1fz587Vnzx7FxsZq/PjxyszMrLV9WVmZfvKTn+jkyZN6//33dejQIa1YsUJRUVFNXDkA4Id8LR56eFw3bXpwpEZ2DVVZhU0vJhzR2D9v0WvbTzB/B4YxdNXV0KFDNXjwYC1ZskSSZLPZFB0drfvvv1+PPvroJe2XL1+uF154QcnJyfLycm7/htLSUpWWXjyNNz8/X9HR0ay6AoBGYrfbtfFAup7a8K3O5pVIklr5eWlaXIymXxvDcRKol2a36qqsrEy7d+9WfHz8xWLMZsXHxysxMbHWe9avX6+4uDjNmTNHYWFh6t27t5555hlVVl6+a3TBggWyWq2OV3R0dIN/FgDARSaTSRP6Ruiz347Rgp/3UUyIn3KLy/XXhCO69tlP9X///kZpueeNLhMthGFBJzs7W5WVlQoLC6txPSwsTOnp6bXec/z4cb3//vuqrKzUxo0b9cc//lELFy7UU089ddn3mTdvnvLy8hyv1NTUBv0cAIDa+Xh56I4h7ZXw8BgtvXOAekUG6Xx5pVZ9cVKjnv9Mv127T0czC4wuE27O0+gC6sJms6lt27Z65ZVX5OHhoYEDB+rMmTN64YUXNH/+/Frv8fb2lre3dxNXCgCo5mGu6uG5qU+4th/N1rItx7Tj2Dm9v/u03t99WuN6huneMZ01oH1ro0uFGzIs6ISGhsrDw0MZGRk1rmdkZCg8PLzWeyIiIuTl5SUPDw/HtR49eig9PV1lZWWyWBj3BQBXZTKZNLJrG43s2kZJqblavuWYPv42Xf/5NkP/+TZDwzoFa/aYLhrVNVQmk8nocuEmDBu6slgsGjhwoBISEhzXbDabEhISFBcXV+s9w4cP19GjR2Wz2RzXDh8+rIiICEIOADQj/aJbafkvB2rzQ6N128B28vIwaefxHE1buUsTXtyuf+9LU0Wl7ccfBPwIQ5eXz507VytWrNDrr7+u7777TrNnz1ZRUZFmzJghSZo6darmzZvnaD979mzl5OTogQce0OHDh7VhwwY988wzmjNnjlEfAQBwFbq0DdALt8Vq6+/GauaIjvKzeOjbs/m6/529un7RVr315Sn24sFVMfxQzyVLluiFF15Qenq6+vXrpxdffFFDhw6VJI0ZM0YxMTFavXq1o31iYqIeeughJSUlKSoqSjNnztQjjzxSYzjrSjjUEwBc1/dFZXoj8ZRW7zih74vLJUmhAd6aOaKj7hrWXkE+zm0tAvdT3+9vw4NOUyPoAIDrKy6r0JqvUrXi8+NKu7AXT6C3p34R10EzhseobaCPwRWiqRF0nETQAYDmo7zSpvVJaVq+9ZiOZBZKkiyeZt02sJ3uGdVJHUL8Da4QTYWg4ySCDgA0PzabXQnJmXppy1HtTcmVJJlN0oS+kbp3dCf1irQaWyAaHUHHSQQdAGi+7Ha7dp3I0bKtx7TlUJbj+phubTR7dGcN6RjM0nQ3RdBxEkEHANzDN2l5ennrcX24P022C99kA9q30uwxXXR997Yymwk87oSg4ySCDgC4l1PnirRi23G99/VplVVU7b3TtW2A7h3dWTf3i5SXh6E7qaCBEHScRNABAPeUWVCiVV+c1JuJp1RQWiFJirT6aNaoTpoyOFp+lmZ16hH+C0HHSQQdAHBv+SXlemtnil7bfkLZhaWSpNZ+Xpp+bUdNjeug1v7spN8cEXScRNABgJahpLxS/9hzWi9vPa6UnGJJkp+l6kT1u0d2VITV1+AKURcEHScRdACgZamotOmjg+latuWYvj2bL0ny8jBpUr8o/Xp0Z3VpG2BwhXAGQcdJBB0AaJnsdrs+P5KtZVuOaufxHEmSySSN6xmm2WO6qF90K2MLxBU1etDZv3+/0w/t27ev022bGkEHALAn5Xst33JM//k2w3EtrlOIZo/prJFdQ9mLxwU1etAxm80ymUy6XPPq35lMJlVWuu5JswQdAEC1o5kFWr71uNbtPaOKC5vx9IoM0uwxnXVj7wh5sBePy2j0oHPq1CmnH9qhQwen2zY1gg4A4L+l5Z7Xq9tO6J1dKTpfXvWX9ZgQP90zqrN+PiBKPl4eBlcI5ug4iaADALic74vKtHrHSb2eeFK5xeWSpDaB3po5oqPuGtpegT5eBlfYcjV60Fm/fr3TD7355pudbtvUCDoAgB9TVFqhd79K1avbjutsXokkKdDHU3eP6KT7r+vC8RIGaJI5Ok49kDk6AAA3UVZh07+Szmj51mM6llUkSfrr7f10S78ogytreer7/e30ASA2m82plyuHHAAA6sLiadZtg6K1+aHRmjmioyTp7S9TDK4KdcFJZwAA/Aiz2aSZIzrKbJK+PJGj41mFRpcEJ9X7hLOioiJt3bpVKSkpKisrq/G73/zmN1ddGAAAriSyla/GdGurT5MztearVM27qYfRJcEJ9Qo6e/fu1U033aTi4mIVFRUpODhY2dnZ8vPzU9u2bQk6AAC3dPvgaH2anKn3d5/Ww+O6yeLJwIirq9c/oYceekgTJ07U999/L19fX+3cuVOnTp3SwIED9ec//7mhawQAwCVc172t2gZ661xRmTb/YFdluK56BZ2kpCQ9/PDDMpvN8vDwUGlpqaKjo/X888/rsccea+gaAQBwCZ4eZk0eFC1JevcrJiU3B/UKOl5eXo7l5m3btlVKStU/bKvVqtTU1IarDgAAFzNlcFXQ2XYkW6k5xQZXgx9Tr6DTv39/ffXVV5Kk0aNH6/HHH9dbb72lBx98UL17927QAgEAcCXRwX4a2TVUEr06zUG9gs4zzzyjiIgISdLTTz+t1q1ba/bs2crKytLLL7/coAUCAOBq7hjSXpK09uvTqqi0GVwNrqReq64GDRrk+O9t27bVpk2bGqwgAABcXXyPMIX4W5RZUKpPkzM1rle40SXhMurVo3PixAkdOXLkkutHjhzRyZMnr7YmAABcmsXTrFsHtpMkvbOL4StXVq+gM336dO3YseOS619++aWmT59+tTUBAODyqiclbz2cpbTc8wZXg8upV9DZu3evhg8ffsn1YcOGKSkp6WprAgDA5XVqE6BhnYJls0vvfc2KY1dVr6BjMplUUFBwyfW8vDwO9QQAtBjVk5Lf+ypVlTa7wdWgNvUKOqNGjdKCBQtqhJrKykotWLBAI0aMaLDiAABwZeN7hauVn5fS8kr0+eEso8tBLeq16uq5557TqFGj1K1bN40cOVKStG3bNuXn5+vTTz9t0AIBAHBVPl4e+nn/dlr5xQm9sytFY7u3Nbok/Jd69ej07NlT+/fv1+TJk5WZmamCggJNnTpVycnJbBgIAGhR7hhSNSk5ITlTmfklBleD/1avHh1JioyM1DPPPNOQtQAA0Ox0DQvUwA6ttfvU91q7+7TmjO1idEn4gXqfL79t2zb94he/0LXXXqszZ85Ikv7+979r+/btDVYcAADNQfWk5He/SpGNSckupV5B5x//+IfGjx8vX19f7dmzR6WlpZKqVl3RywMAaGkm9IlQoI+nUnPOa8exc0aXgx+oV9B56qmntHz5cq1YsUJeXl6O68OHD9eePXsarDgAAJoDX4uHJvWLksROya6mXkHn0KFDGjVq1CXXrVarcnNzr7YmAACandsvTEr+z7fpOldYanA1qFavoBMeHq6jR49ecn379u3q1KnTVRcFAEBz0yvSqth2VpVX2vWPPaeNLgcX1CvozJo1Sw888IC+/PJLmUwmpaWl6a233tLDDz+s2bNnN3SNAAA0C7dXT0relSq7nUnJrqBey8sfffRR2Ww2XX/99SouLtaoUaPk7e2t3/3ud7r77rsbukYAAJqFibGRevLDb3U8u0hfnsjRsE4hRpfU4tX7rKv/9//+n3JycnTw4EHt3LlTWVlZslqt6tixY0PXCABAsxDg7alb+kVKkh75x359m5ZvcEWoU9ApLS3VvHnzNGjQIA0fPlwbN25Uz5499c0336hbt27661//qoceeqixagUAwOX975guimrlq1PnivWzl77gZHODmex1GER85JFH9PLLLys+Pl47duxQVlaWZsyYoZ07d+qxxx7TbbfdJg8Pj8as96rl5+fLarUqLy9PQUFBRpcDAHBD3xeVae57SfrsUNVBn5MHtdOfbuktHy/X/o50ZfX9/q5Tj87atWv1xhtv6P3339d//vMfVVZWqqKiQvv27dPtt9/u8iEHAICm0NrfotemDdbvxneT2SS99/Vp/eylHTqZXWR0aS1OnXp0LBaLTpw4oaioqk2RfH19tWvXLvXp06fRCmxo9OgAAJrSF0ez9Zt39upcUZkCvT31wm2xuqF3uNFlNTtN0qNTWVkpi8Xi+NnT01MBAQF1eQQAAC3K8C6h2vCbkRrUobUKSit075u79czG71ReaTO6tBahTj06ZrNZN954o7y9vSVJ//73v3XdddfJ39+/RrsPPvigYatsQPToAACMUF5p0/ObkrVi2wlJ0uCY1lpy5wCFBfkYXFnzUN/v7zoFnRkzZjjVbtWqVU4X0NQIOgAAI206eFa/W7tfBaUVCg2w6MU7+uvazqFGl+XymiTouAOCDgDAaCeyizT7zd1KTi+Q2SQ9PK6bZo/uLLPZZHRpLqtJ5ugAAICr1zHUX+vmDNdtA9vJZpde+PiQ7n7ja+UWlxldmtsh6AAAYAAfLw+9cFusnv+fvvL2NOvT5ExNeHG79p/ONbo0t0LQAQDAQJMHR+uD/71WHUL8dCb3vG5dlqg3d57iUNAGQtABAMBgvSKtWn/fCI3rGaaySpv+sO6gHlqTpOKyCqNLa/YIOgAAuACrr5de/uVA/b+besjDbNK6pDTdsuQLHc0sNLq0Zo2gAwCAizCZTJo1qpPemTVMbQO9dSSzUDcv2a5/70szurRmyyWCztKlSxUTEyMfHx8NHTpUu3btcuq+d999VyaTSZMmTWrcAgEAaEJDOgbrw9+MUFynEBWXVer+d/bqifXfqKyC3ZTryvCgs2bNGs2dO1fz58/Xnj17FBsbq/HjxyszM/OK9508eVK//e1vNXLkyCaqFACAptM20Ed/nzlEc8Z2liSt3nFSk19O1Jnc8wZX1rwYHnQWLVqkWbNmacaMGerZs6eWL18uPz8/rVy58rL3VFZW6q677tL//d//qVOnTk1YLQAATcfTw6zfje+uldMHyerrpaTUXP30xW3aejjL6NKaDUODTllZmXbv3q34+HjHNbPZrPj4eCUmJl72vj/96U9q27atZs6c+aPvUVpaqvz8/BovAACak+u6h+nD+0eoT5RV3xeXa/qqXVq0+bAqbSxB/zGGBp3s7GxVVlYqLCysxvWwsDClp6fXes/27dv12muvacWKFU69x4IFC2S1Wh2v6Ojoq64bAICmFh3sp7X3xumuoe1lt0svJhzR9FW7dK6w1OjSXJrhQ1d1UVBQoF/+8pdasWKFQkOdOwBt3rx5ysvLc7xSU1MbuUoAABqHj5eHnv5ZH/1lSqx8vTy07Ui2Jry4XbtP5RhdmsvyNPLNQ0ND5eHhoYyMjBrXMzIyFB4efkn7Y8eO6eTJk5o4caLjms1WNQPd09NThw4dUufOnWvc4+3tLW9v70aoHgAAY/ysfzv1irTq3jd363hWkaa8vFPzbuqhXw2PkcnEwaA/ZGiPjsVi0cCBA5WQkOC4ZrPZlJCQoLi4uEvad+/eXQcOHFBSUpLjdfPNN2vs2LFKSkpiWAoA0GJcExao9feN0IS+Eaqw2fXkh99qztt7VFBSbnRpLsXQHh1Jmjt3rqZNm6ZBgwZpyJAhWrx4sYqKijRjxgxJ0tSpUxUVFaUFCxbIx8dHvXv3rnF/q1atJOmS6wAAuLsAb08tuaO/hsQE66kN32rjgXQlny3QS78YoO7hQUaX5xIMDzpTpkxRVlaWHn/8caWnp6tfv37atGmTY4JySkqKzOZmNZUIAIAmYzKZNO3aGPVpZ9V9b+3R8ewiTVr6hZ6e1Ef/M7Cd0eUZzmRvYcej5ufny2q1Ki8vT0FBpF0AgPvIKSrTg2uS9PmFfXbuGNJe8yf2lI+Xh8GVXb36fn/TVQIAgJsI9rdo1fTBeij+GplM0ju7UvQ/y3Yo5Vyx0aUZhqADAIAb8TCb9EB8V73xqyEK9rfom7R8/fRv2/TJtxk/frMbIugAAOCGRnZtow/vH6H+7Vspv6RCd7/xtZ79KFkVlS3rYFCCDgAAbiqyla/W3BOnGcNjJEnLtx7TXa9+qcyCEmMLa0IEHQAA3JjF06z5E3tp6Z0D5G/x0JcncjThxe3aefyc0aU1CYIOAAAtwIS+EVp//wh1CwtUVkGp7lyxU8u2HJO7L74m6AAA0EJ0bhOgf865Vj/vHyWbXXpuU7JmvbFbeefddzdlgg4AAC2In8VTCyfH6pmf9ZHFw6xPvsvQT/+2TQfP5BldWqMg6AAA0MKYTCbdObS9/jH7WkUH+yo157x+vmyH3tmV4nZDWQQdAABaqD7trPrwvpGK79FWZRU2zfvggF7bfsLoshoUQQcAgBbM6uelV345SPeN7SJJWvXFSdls7tOrQ9ABAKCFM5tNuu+6Lgr09tSZ3PP66mSO0SU1GIIOAACQj5eHbugdLklal5RmcDUNh6ADAAAkST/rHyVJ2rA/TaUVlQZX0zAIOgAAQJI0tFOIwoN8lF9Soc+Ss4wup0EQdAAAgKSqk89v7hcpSfpX0hmDq2kYBB0AAOAwqV/V8FXCd5lusWMyQQcAADj0iAhUt7BAlVXatOngWaPLuWoEHQAA4GAymXRL/6rhq3/ubf7DVwQdAABQwy0Xhq92Hs9RWu55g6u5OgQdAABQQ1QrXw3pGCxJWr+vee+pQ9ABAACXqN5TZ10zH74i6AAAgEvc1DtCFg+zktML9N3ZfKPLqTeCDgAAuITVz0tju7eRJK1rxnvqEHQAAECtqoev/rU3rdmeaE7QAQAAtRrTra2CfDyVnl+inSfOGV1OvRB0AABArXy8PHRTnwhJVb06zRFBBwAAXNakC8NXGw+cVUl58zvRnKADAAAua0hMsCKtPioordBnyZlGl1NnBB0AAHBZZrNJN1/YKbk5HglB0AEAAFdUvfrqs0OZyi0uM7iauiHoAACAK+oWHqju4YEqr7Rr44F0o8upE4IOAAD4Uc31SAiCDgAA+FE394uUySTtOpmj098XG12O0wg6AADgR0VYfTWsY4gk6V9JzWdPHYIOAABwyrheYZKkpNRcYwupA4IOAABwSoTVV5KUXVhqcCXOI+gAAACnhAZYJEnnCpvPEnOCDgAAcEpogLckenQAAIAbCg2sCjrFZZUqLqswuBrnEHQAAIBT/C0e8vasig7NZfiKoAMAAJxiMpkcw1dZzWT4iqADAACcVj18RY8OAABwO6H+VSuvmsuEZIIOAABwmmPlVQFBBwAAuJnQwAt76RQxdAUAANxMiD+TkQEAgJuqnozM0BUAAHA71ZORGboCAABux9Gjw9AVAABwN9WrrnKLy1VeaTO4mh9H0AEAAE5r5eslD7NJkpTTDIavCDoAAMBpZrNJwRfm6WQ1gwnJBB0AAFAnjk0Dm8E8HYIOAACok9CACyuvmsF5VwQdAABQJ/To1NHSpUsVExMjHx8fDR06VLt27bps2xUrVmjkyJFq3bq1Wrdurfj4+Cu2BwAADau6R4eg44Q1a9Zo7ty5mj9/vvbs2aPY2FiNHz9emZmZtbbfsmWL7rjjDn322WdKTExUdHS0xo0bpzNnzjRx5QAAtEwhF3p0GLpywqJFizRr1izNmDFDPXv21PLly+Xn56eVK1fW2v6tt97S//7v/6pfv37q3r27Xn31VdlsNiUkJDRx5QAAtEzVQ1fN4bwrQ4NOWVmZdu/erfj4eMc1s9ms+Ph4JSYmOvWM4uJilZeXKzg4uNbfl5aWKj8/v8YLAADU38WhK3p0rig7O1uVlZUKCwurcT0sLEzp6elOPeORRx5RZGRkjbD0QwsWLJDVanW8oqOjr7puAABaslDH0BU9Oo3q2Wef1bvvvqt//vOf8vHxqbXNvHnzlJeX53ilpqY2cZUAALgXR9ApKpPNZje4mivzNPLNQ0ND5eHhoYyMjBrXMzIyFB4efsV7//znP+vZZ5/VJ598or59+162nbe3t7y9vRukXgAAIMfOyJU2u3LPlzt+dkWG9uhYLBYNHDiwxkTi6onFcXFxl73v+eef15NPPqlNmzZp0KBBTVEqAAC4wOJpltXXS5LrD18ZPnQ1d+5crVixQq+//rq+++47zZ49W0VFRZoxY4YkaerUqZo3b56j/XPPPac//vGPWrlypWJiYpSenq709HQVFhYa9REAAGhxqicku/rKK0OHriRpypQpysrK0uOPP6709HT169dPmzZtckxQTklJkdl8MY8tW7ZMZWVluvXWW2s8Z/78+XriiSeasnQAAFqskABvHcsqcvmVV4YHHUm67777dN9999X6uy1bttT4+eTJk41fEAAAuKI2zWTlleFDVwAAoPlpLsdAEHQAAECdVR8DkV3g2kNXBB0AAFBnF/fSoUcHAAC4mYurrujRAQAAbubi0BU9OgAAwM20+cHQld3uusdAEHQAAECdhQZWDV2VlNtUVFZpcDWXR9ABAAB15mfxlK+XhyTXHr4i6AAAgHqp7tVx5ZVXBB0AAFAv1UvMs1x4Lx2CDgAAqJcQ/wsrr1x4d2SCDgAAqJc21UNXLryXDkEHAADUS/XQFT06AADA7YT4u/7BngQdAABQL6GBFzYNZOgKAAC4G4auAACA27p4sCdBBwAAuJnqHp2CkgqVVrjmMRAEHQAAUC9BPl7yNJskue48HYIOAACoF7PZpJAA195Lh6ADAADqzdUnJBN0AABAvYVUn3dF0AEAAO4mlKErAADgrtowdAUAANxV9WRkgg4AAHA71ZORGboCAABuh1VXAADAbTF0BQAA3Fb1ZOScojJV2uwGV3Mpgg4AAKi3YP+qHh2bXfq+2PXm6RB0AABAvXl6mNXaz0uSaw5fEXQAAMBVceWVVwQdAABwVVx55RVBBwAAXJXqlVdZBQQdAADgZhxDV0UMXQEAADdTfbBnNj06AADA3TBHBwAAuC2GrgAAgNsKYegKAAC4q4tDV2Wy213rGAiCDgAAuCrVQaes0qaC0gqDq6mJoAMAAK6Kr8VD/hYPSa43fEXQAQAAVy008OLwlSsh6AAAgKt28bwrenQAAICbCfG/sPKKoAMAANxN9dBVFkNXAADA3TB0BQAA3JbjvCuCDgAAcDc/3DTQlRB0AADAVWPoCgAAuC3HeVf06AAAAHdT3aNTWFqhkvJKg6u5iKADAACuWpCPpyweVbHClSYkE3QAAMBVM5lMLjl8RdABAAANwrHyyoUO9iToAACABlHdo3OuiKBTw9KlSxUTEyMfHx8NHTpUu3btumL7tWvXqnv37vLx8VGfPn20cePGJqoUAABcjivupWN40FmzZo3mzp2r+fPna8+ePYqNjdX48eOVmZlZa/sdO3bojjvu0MyZM7V3715NmjRJkyZN0sGDB5u4cgAA8EPVQSeLoauLFi1apFmzZmnGjBnq2bOnli9fLj8/P61cubLW9n/96191ww036He/+5169OihJ598UgMGDNCSJUuauHIAAPBDoY6hK3p0JEllZWXavXu34uPjHdfMZrPi4+OVmJhY6z2JiYk12kvS+PHjL9u+tLRU+fn5NV4AAKDhMRn5v2RnZ6uyslJhYWE1roeFhSk9Pb3We9LT0+vUfsGCBbJarY5XdHR0wxQPAABqCA3wlofZJJvdbnQpDoYPXTW2efPmKS8vz/FKTU01uiQAANxSXOcQHXnqRq35dZzRpTh4GvnmoaGh8vDwUEZGRo3rGRkZCg8Pr/We8PDwOrX39vaWt7d3wxQMAAAuy8NsMrqESxjao2OxWDRw4EAlJCQ4rtlsNiUkJCgurvY0GBcXV6O9JG3evPmy7QEAQMtlaI+OJM2dO1fTpk3ToEGDNGTIEC1evFhFRUWaMWOGJGnq1KmKiorSggULJEkPPPCARo8erYULF2rChAl699139fXXX+uVV14x8mMAAAAXZHjQmTJlirKysvT4448rPT1d/fr106ZNmxwTjlNSUmQ2X+x4uvbaa/X222/rD3/4gx577DF17dpV69atU+/evY36CAAAwEWZ7HYXmhrdBPLz82W1WpWXl6egoCCjywEAAE6o7/e326+6AgAALRdBBwAAuC2CDgAAcFsEHQAA4LYIOgAAwG0RdAAAgNsi6AAAALdF0AEAAG6LoAMAANyW4UdANLXqjaDz8/MNrgQAADir+nu7rgc6tLigU1BQIEmKjo42uBIAAFBXBQUFslqtTrdvcWdd2Ww2paWlKTAwUCaTqUneMz8/X9HR0UpNTeV8LQBAi3S134V2u10FBQWKjIyscdj3j2lxPTpms1nt2rUz5L2DgoIIOgCAFu1qvgvr0pNTjcnIAADAbRF0AACA2yLoNAFvb2/Nnz9f3t7eRpcCAIAhjPoubHGTkQEAQMtBjw4AAHBbBB0AAOC2CDoAAMBtEXQAAIDbIug4YenSpYqJiZGPj4+GDh2qXbt2XbH92rVr1b17d/n4+KhPnz7auHFjjd9/8MEHGjdunEJCQmQymZSUlHTJM37961+rc+fO8vX1VZs2bXTLLbcoOTm5IT8WAAA/6vPPP9fEiRMVGRkpk8mkdevW/eg9W7Zs0YABA+Tt7a0uXbpo9erVdX7mE088oe7du8vf31+tW7dWfHy8vvzyyzrXT9D5EWvWrNHcuXM1f/587dmzR7GxsRo/frwyMzNrbb9jxw7dcccdmjlzpvbu3atJkyZp0qRJOnjwoKNNUVGRRowYoeeee+6y7ztw4ECtWrVK3333nT7++GPZ7XaNGzdOlZWVDf4ZAQC4nKKiIsXGxmrp0qVOtT9x4oQmTJigsWPHKikpSQ8++KDuvvtuffzxx3V65jXXXKMlS5bowIED2r59u2JiYjRu3DhlZWXVqX6Wl/+IoUOHavDgwVqyZImkqrOyoqOjdf/99+vRRx+9pP2UKVNUVFSkDz/80HFt2LBh6tevn5YvX16j7cmTJ9WxY0ft3btX/fr1u2Id+/fvV2xsrI4eParOnTtf/QcDAKCOTCaT/vnPf2rSpEmXbfPII49ow4YNNf6Cf/vttys3N1ebNm2q1zOlqrOyrFarPvnkE11//fVO10yPzhWUlZVp9+7dio+Pd1wzm82Kj49XYmJirfckJibWaC9J48ePv2x7ZxQVFWnVqlXq2LEjp64DAFxaY3wPlpWV6ZVXXpHValVsbGyd7iXoXEF2drYqKysVFhZW43pYWJjS09NrvSc9Pb1O7a/kpZdeUkBAgAICAvTRRx9p8+bNslgsdX4OAABN5XLfg/n5+Tp//nydnvXhhx8qICBAPj4++stf/qLNmzcrNDS0Ts8g6Liwu+66S3v37tXWrVt1zTXXaPLkySopKTG6LAAAmkT1PJ8dO3bohhtu0OTJky87R/ZyCDpXEBoaKg8PD2VkZNS4npGRofDw8FrvCQ8Pr1P7K7FareratatGjRql999/X8nJyfrnP/9Z5+cAANBULvc9GBQUJF9f3zo9y9/fX126dNGwYcP02muvydPTU6+99lqdnkHQuQKLxaKBAwcqISHBcc1msykhIUFxcXG13hMXF1ejvSRt3rz5su2dZbfbZbfbVVpaelXPAQCgMTXW96BU9R1c1+9Bz6t+Vzc3d+5cTZs2TYMGDdKQIUO0ePFiFRUVacaMGZKkqVOnKioqSgsWLJAkPfDAAxo9erQWLlyoCRMm6N1339XXX3+tV155xfHMnJwcpaSkKC0tTZJ06NAhSVUpODw8XMePH9eaNWs0btw4tWnTRqdPn9azzz4rX19f3XTTTU38JwAAaMkKCwt19OhRx88nTpxQUlKSgoOD1b59e82bN09nzpzRG2+8IUm69957tWTJEv3+97/Xr371K3366ad67733tGHDBqefWVRUpKefflo333yzIiIilJ2draVLl+rMmTO67bbb6vYB7PhRf/vb3+zt27e3WywW+5AhQ+w7d+50/G706NH2adOm1Wj/3nvv2a+55hq7xWKx9+rVy75hw4Yav1+1apVd0iWv+fPn2+12u/3MmTP2G2+80d62bVu7l5eXvV27dvY777zTnpyc3NgfFQCAGj777LNav7Oqv/umTZtmHz169CX39OvXz26xWOydOnWyr1q1qk7PPH/+vP1nP/uZPTIy0m6xWOwRERH2m2++2b5r1646188+OgAAwG0xRwcAALgtgg4AAHBbBB0AAOC2CDoAAMBtEXQAAIDbIugAAAC3RdABAABui6ADAADcFkEHgFsxmUxat25dg7cF0DwRdAA0munTp8tkMslkMslisahLly7605/+pIqKikZ7z7Nnz+rGG29s8LYAmicO9QTQqG644QatWrVKpaWl2rhxo+bMmSMvLy/NmzevRruysjJZLJarfr/w8PBGaQugeaJHB0Cj8vb2Vnh4uDp06KDZs2crPj5e69ev1/Tp0zVp0iQ9/fTTioyMVLdu3SRJqampmjx5slq1aqXg4GDdcsstOnnyZI1nrly5Ur169ZK3t7ciIiJ03333OX73w+GosrIy3XfffYqIiJCPj486dOigBQsW1NpWkg4cOKDrrrtOvr6+CgkJ0T333KPCwkLH76tr/vOf/6yIiAiFhIRozpw5Ki8vb/g/OAANgqADoEn5+vqqrKxMkpSQkKBDhw5p8+bN+vDDD1VeXq7x48crMDBQ27Zt0xdffKGAgADdcMMNjnuWLVumOXPm6J577tGBAwe0fv16denSpdb3evHFF7V+/Xq99957OnTokN566y3FxMTU2raoqEjjx49X69at9dVXX2nt2rX65JNPaoQoSfrss8907NgxffbZZ3r99de1evVqrV69usH+fAA0LIauADQJu92uhIQEffzxx7r//vuVlZUlf39/vfrqq44hqzfffFM2m02vvvqqTCaTJGnVqlVq1aqVtmzZonHjxumpp57Sww8/rAceeMDx7MGDB9f6nikpKeratatGjBghk8mkDh06XLa+t99+WyUlJXrjjTfk7+8vSVqyZIkmTpyo5557TmFhYZKk1q1ba8mSJfLw8FD37t01YcIEJSQkaNasWQ3y5wSgYdGjA6BRffjhhwoICJCPj49uvPFGTZkyRU888YQkqU+fPjXm5ezbt09Hjx5VYGCgAgICFBAQoODgYJWUlOjYsWPKzMxUWlqarr/+eqfee/r06UpKSlK3bt30m9/8Rv/5z38u2/a7775TbGysI+RI0vDhw2Wz2XTo0CHHtV69esnDw8Pxc0REhDIzM5394wDQxOjRAdCoxo4dq2XLlslisSgyMlKenhf/tfPDUCFJhYWFGjhwoN56661LntOmTRuZzXX7u9mAAQN04sQJffTRR/rkk080efJkxcfH6/3336/fh5Hk5eVV42eTySSbzVbv5wFoXAQdAI3K39//snNo/tuAAQO0Zs0atW3bVkFBQbW2iYmJUUJCgsaOHevUM4OCgjRlyhRNmTJFt956q2644Qbl5OQoODi4RrsePXpo9erVKioqcgSwL774Qmaz2TFRGkDzw9AVAJdx1113KTQ0VLfccou2bdumEydOaMuWLfrNb36j06dPS5KeeOIJLVy4UC+++KKOHDmiPXv26G9/+1utz1u0aJHeeecdJScn6/Dhw1q7dq3Cw8PVqlWrWt/bx8dH06ZN08GDB/XZZ5/p/vvv1y9/+UvH/BwAzQ9BB4DL8PPz0+eff6727dvr5z//uXr06KGZM2eqpKTE0cMzbdo0LV68WC+99JJ69eqln/70pzpy5EitzwsMDNTzzz+vQYMGafDgwTp58qQ2btxY6xCYn5+fPv74Y+Xk5Gjw4MG69dZbdf3112vJkiWN+pkBNC6T3W63G10EAABAY6BHBwAAuC2CDgAAcFsEHQAA4LYIOgAAwG0RdAAAgNsi6AAAALdF0AEAAG6LoAMAANwWQQcAALgtgg4AAHBbBB0AAOC2/j9Vp5u5Sq+BwwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["f = open(\"data_file.csv\", \"w\")\n","w = csv.writer(f)\n","_ = w.writerow([\"precision\", \"recall\"])\n","w.writerows([[0.013,0.951],\n","             [0.376,0.851],\n","             [0.441,0.839],\n","             [0.570,0.758],\n","             [0.635,0.674],\n","             [0.721,0.604],\n","             [0.837,0.531],\n","             [0.860,0.453],\n","             [0.962,0.348],\n","             [0.982,0.273],\n","             [1.0,0.0]])\n","f.close()\n","plot_data('data_file.csv')\n"]},{"cell_type":"markdown","metadata":{"id":"tSmW0Y5nYTP5"},"source":["<h1 id=\"generator-for-exercise-4\">** Generator (for Exercise 4)**</h1>\n"]},{"cell_type":"markdown","metadata":{"id":"BRDjhzIlYTP6"},"source":["<font size=\"4px\"><p>Generator class for the GAN</p>\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZvQNDFAYTP6"},"outputs":[],"source":["# You can copy this code to your personal pipeline project or execute it here.\n","import torch.nn as nn\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(100, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 784),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        output = output.view(x.size(0), 1, 28, 28)\n","        return output\n"]},{"cell_type":"markdown","metadata":{"id":"63rOKIirYTP6"},"source":["<h1 id=\"discriminator-for-exercise-4\">** Discriminator (for Exercise 4)**</h1>\n"]},{"cell_type":"markdown","metadata":{"id":"gy6gG_RvYTP6"},"source":["<font size=\"4px\"><p>Discriminator class for the GAN</p>\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQkPy9YNYTP6"},"outputs":[],"source":["# You can copy this code to your personal pipeline project or execute it here.\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    Discriminator class for the GAN\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(784, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), 784)\n","        output = self.model(x)\n","        return output\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sMBNPQNTYTP6"},"source":["<h1 id=\"exercise-4\">** Exercise 4**</h1>\n"]},{"cell_type":"markdown","metadata":{"id":"KsKzArplYTP6"},"source":["<font size=\"4px\"><p>The method trains a Generative Adversarial Network and is based on: <a href=\"https://realpython.com/generative-adversarial-networks/\">https://realpython.com/generative-adversarial-networks/</a></p>\n","<p>The Generator network tries to generate convincing images of handwritten digits. The Discriminator needs to detect if the image was created by the Generater or if the image is a real image from a known dataset (MNIST). If both the Generator and the Discriminator are optimized, the Generator is able to create images that are difficult to distinguish from real images. This is goal of a GAN.</p>\n","<p>This code produces the expected results at first attempt at about 50 epochs.</p>\n","<dl>\n","<dt>param batch_size</dt>\n","<dd><p>The number of images to train in one epoch.</p>\n","</dd>\n","<dt>param num_epochs</dt>\n","<dd><p>The number of epochs to train the gan.</p>\n","</dd>\n","<dt>param device</dt>\n","<dd><p>The computing device to use. If CUDA is installed and working then <span class=\"title-ref\">cuda:0</span> is chosen otherwise 'cpu' is chosen. Note: Training a GAN on the CPU is very slow.</p>\n","</dd>\n","</dl>\n","<p><strong>This method is part of a series of debugging exercises.</strong> <strong>Each Python method of this series contains bug that needs to be found.</strong></p>\n","<p>It contains at least two bugs: one structural bug and one cosmetic bug. Both bugs are from the original tutorial.</p>\n","<div class=\"line-block\"><code>1   Changing the batch_size from 32 to 64 triggers the structural bug.</code><br />\n","<code>2   Can you also spot the cosmetic bug?</code><br />\n","<code>Note: to fix this bug a thorough understanding of GANs is not necessary.</code></div>\n","<p>Change the batch size to 64 to trigger the bug with message: ValueError: \"Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\"</p>\n","</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mvwsc5eYTP6"},"outputs":[],"source":["def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n","    \"\"\"\n","    The method trains a Generative Adversarial Network and is based on:\n","    https://realpython.com/generative-adversarial-networks/\n","\n","    The Generator network tries to generate convincing images of handwritten digits.\n","    The Discriminator needs to detect if the image was created by the Generater or if the image is a real image from\n","    a known dataset (MNIST).\n","    If both the Generator and the Discriminator are optimized, the Generator is able to create images that are difficult\n","    to distinguish from real images. This is goal of a GAN.\n","\n","    This code produces the expected results at first attempt at about 50 epochs.\n","\n","    :param batch_size: The number of images to train in one epoch.\n","    :param num_epochs: The number of epochs to train the gan.\n","    :param device: The computing device to use. If CUDA is installed and working then `cuda:0` is chosen\n","        otherwise 'cpu' is chosen. Note: Training a GAN on the CPU is very slow.\n","\n","    **This method is part of a series of debugging exercises.**\n","    **Each Python method of this series contains bug that needs to be found.**\n","\n","    It contains at least two bugs: one structural bug and one cosmetic bug. Both bugs are from the original tutorial.\n","\n","    | ``1   Changing the batch_size from 32 to 64 triggers the structural bug.``\n","    | ``2   Can you also spot the cosmetic bug?``\n","    | ``Note: to fix this bug a thorough understanding of GANs is not necessary.``\n","\n","    Change the batch size to 64 to trigger the bug with message:\n","    ValueError: \"Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\"\n","\n","    >>> train_gan(batch_size=32, num_epochs=100)\n","    \"\"\"\n","    # Add/adjust code.\n","\n","    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","    try:\n","        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n","    except:\n","        print(\"Failed to download MNIST, retrying with different URL\")\n","        # see: https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n","        torchvision.datasets.MNIST.resources = [\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n","             'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n","             'd53e105ee54ea40749a09fcbcd1e9432'),\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n","             '9fb629c4189551a2d022fa330f9573f3'),\n","            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz',\n","             'ec29112dd5afa0611ce80d1b7f02629c')\n","        ]\n","        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n","\n","    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","\n","    # example data\n","    real_samples, mnist_labels = next(iter(train_loader))\n","\n","    fig = plt.figure()\n","    for i in range(16):\n","        sub = fig.add_subplot(4, 4, 1 + i)\n","        sub.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n","        sub.axis('off')\n","\n","    fig.tight_layout()\n","    fig.suptitle(\"Real images\")\n","    display(fig)\n","\n","    time.sleep(5)\n","\n","    # Set up training\n","    discriminator = Discriminator().to(device)\n","    generator = Generator().to(device)\n","    lr = 0.0001\n","    loss_function = nn.BCELoss()\n","    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n","    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n","\n","    # train\n","    for epoch in range(num_epochs):\n","        for n, (real_samples, mnist_labels) in enumerate(train_loader):\n","\n","            # Data for training the discriminator\n","            real_samples = real_samples.to(device=device)\n","            real_samples_labels = torch.ones((batch_size, 1)).to(device=device)\n","            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n","            generated_samples = generator(latent_space_samples)\n","            generated_samples_labels = torch.zeros((batch_size, 1)).to(device=device)\n","            all_samples = torch.cat((real_samples, generated_samples))\n","            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n","\n","            # Training the discriminator\n","            discriminator.zero_grad()\n","            output_discriminator = discriminator(all_samples)\n","            print(output_discriminator.shape, all_samples_labels.shape)\n","            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n","            loss_discriminator.backward()\n","            optimizer_discriminator.step()\n","\n","            # Data for training the generator\n","            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n","\n","            # Training the generator\n","            generator.zero_grad()\n","            generated_samples = generator(latent_space_samples)\n","            output_discriminator_generated = discriminator(generated_samples)\n","            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n","            loss_generator.backward()\n","            optimizer_generator.step()\n","\n","            # Show loss and samples generated\n","            if n == batch_size - 1:\n","                name = f\"Generate images\\n Epoch: {epoch} Loss D.: {loss_discriminator:.2f} Loss G.: {loss_generator:.2f}\"\n","                generated_samples = generated_samples.detach().cpu().numpy()\n","                fig = plt.figure()\n","                for i in range(16):\n","                    sub = fig.add_subplot(4, 4, 1 + i)\n","                    sub.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n","                    sub.axis('off')\n","                fig.suptitle(name)\n","                fig.tight_layout()\n","                clear_output(wait=False)\n","                display(fig)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXU_ST-vYTP7"},"outputs":[],"source":["train_gan(batch_size=32, num_epochs=100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H_80HwPqYTP7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"61aa1a20-5ede-4aa6-80a0-5653ceafbbb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Batch: 0, Loss D.: 0.7093, Loss G.: 0.6697\n","Epoch: 0, Batch: 100, Loss D.: 0.2400, Loss G.: 1.2984\n","Epoch: 0, Batch: 200, Loss D.: 0.1251, Loss G.: 1.6460\n","Epoch: 0, Batch: 300, Loss D.: 0.1726, Loss G.: 5.1390\n","Epoch: 0, Batch: 400, Loss D.: 0.1134, Loss G.: 6.9148\n","Epoch: 0, Batch: 500, Loss D.: 0.0607, Loss G.: 4.3445\n","Epoch: 0, Batch: 600, Loss D.: 0.1799, Loss G.: 3.0695\n","Epoch: 0, Batch: 700, Loss D.: 0.0255, Loss G.: 4.2909\n","Epoch: 0, Batch: 800, Loss D.: 0.0252, Loss G.: 3.4937\n","Epoch: 0, Batch: 900, Loss D.: 0.0165, Loss G.: 3.7644\n","Epoch: 1, Batch: 0, Loss D.: 0.0132, Loss G.: 5.1517\n","Epoch: 1, Batch: 100, Loss D.: 0.1404, Loss G.: 6.5350\n","Epoch: 1, Batch: 200, Loss D.: 0.0421, Loss G.: 6.1187\n","Epoch: 1, Batch: 300, Loss D.: 0.0213, Loss G.: 6.6646\n","Epoch: 1, Batch: 400, Loss D.: 0.0305, Loss G.: 5.5795\n","Epoch: 1, Batch: 500, Loss D.: 0.0624, Loss G.: 5.6590\n","Epoch: 1, Batch: 600, Loss D.: 0.0163, Loss G.: 4.8968\n","Epoch: 1, Batch: 700, Loss D.: 0.0154, Loss G.: 6.2753\n","Epoch: 1, Batch: 800, Loss D.: 0.0140, Loss G.: 5.7062\n","Epoch: 1, Batch: 900, Loss D.: 0.0344, Loss G.: 6.1577\n","Epoch: 2, Batch: 0, Loss D.: 0.0092, Loss G.: 5.9812\n","Epoch: 2, Batch: 100, Loss D.: 0.0241, Loss G.: 6.8345\n","Epoch: 2, Batch: 200, Loss D.: 0.0152, Loss G.: 5.0125\n","Epoch: 2, Batch: 300, Loss D.: 0.0357, Loss G.: 9.2636\n","Epoch: 2, Batch: 400, Loss D.: 0.0402, Loss G.: 5.6661\n","Epoch: 2, Batch: 500, Loss D.: 0.0299, Loss G.: 6.8287\n","Epoch: 2, Batch: 600, Loss D.: 0.0420, Loss G.: 3.8855\n","Epoch: 2, Batch: 700, Loss D.: 0.0031, Loss G.: 12.1619\n","Epoch: 2, Batch: 800, Loss D.: 0.0287, Loss G.: 5.7541\n","Epoch: 2, Batch: 900, Loss D.: 0.0578, Loss G.: 6.7613\n","Epoch: 3, Batch: 0, Loss D.: 0.0130, Loss G.: 5.6966\n","Epoch: 3, Batch: 100, Loss D.: 0.0008, Loss G.: 9.9889\n","Epoch: 3, Batch: 200, Loss D.: 0.0782, Loss G.: 5.9612\n","Epoch: 3, Batch: 300, Loss D.: 0.0309, Loss G.: 6.4709\n","Epoch: 3, Batch: 400, Loss D.: 0.0186, Loss G.: 7.6712\n","Epoch: 3, Batch: 500, Loss D.: 0.0187, Loss G.: 6.2545\n","Epoch: 3, Batch: 600, Loss D.: 0.0145, Loss G.: 7.5994\n","Epoch: 3, Batch: 700, Loss D.: 0.0126, Loss G.: 8.3834\n","Epoch: 3, Batch: 800, Loss D.: 0.0016, Loss G.: 8.9433\n","Epoch: 3, Batch: 900, Loss D.: 0.0058, Loss G.: 8.3771\n","Epoch: 4, Batch: 0, Loss D.: 0.0151, Loss G.: 6.6322\n","Epoch: 4, Batch: 100, Loss D.: 0.0231, Loss G.: 5.5626\n","Epoch: 4, Batch: 200, Loss D.: 0.0093, Loss G.: 6.1447\n","Epoch: 4, Batch: 300, Loss D.: 0.0491, Loss G.: 7.7906\n","Epoch: 4, Batch: 400, Loss D.: 0.1038, Loss G.: 6.3013\n","Epoch: 4, Batch: 500, Loss D.: 0.0250, Loss G.: 6.2843\n","Epoch: 4, Batch: 600, Loss D.: 0.0719, Loss G.: 10.3378\n","Epoch: 4, Batch: 700, Loss D.: 0.0401, Loss G.: 11.8711\n","Epoch: 4, Batch: 800, Loss D.: 0.0066, Loss G.: 4.9119\n"]}],"source":["import torch\n","import torchvision\n","from torch import nn\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output\n","import time\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(100, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 784),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        output = output.view(x.size(0), 1, 28, 28)\n","        return output\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(784, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), 784)\n","        output = self.model(x)\n","        return output\n","\n","def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n","    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","    train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","\n","    discriminator = Discriminator().to(device)\n","    generator = Generator().to(device)\n","    lr = 0.0001\n","    loss_function = nn.BCELoss()\n","    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n","    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n","\n","    for epoch in range(num_epochs):\n","        for n, (real_samples, _) in enumerate(train_loader):\n","            current_batch_size = real_samples.size(0)\n","            real_samples = real_samples.to(device=device)\n","            real_samples_labels = torch.ones((current_batch_size, 1)).to(device=device)\n","            latent_space_samples = torch.randn((current_batch_size, 100)).to(device=device)\n","            generated_samples = generator(latent_space_samples)\n","            generated_samples_labels = torch.zeros((current_batch_size, 1)).to(device=device)\n","            all_samples = torch.cat((real_samples, generated_samples))\n","            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n","\n","            discriminator.zero_grad()\n","            output_discriminator = discriminator(all_samples)\n","            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n","            loss_discriminator.backward()\n","            optimizer_discriminator.step()\n","\n","            latent_space_samples = torch.randn((current_batch_size, 100)).to(device=device)\n","            generator.zero_grad()\n","            generated_samples = generator(latent_space_samples)\n","            output_discriminator_generated = discriminator(generated_samples)\n","            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n","            loss_generator.backward()\n","            optimizer_generator.step()\n","\n","            if n % 100 == 0:\n","                print(f\"Epoch: {epoch}, Batch: {n}, Loss D.: {loss_discriminator.item():.4f}, Loss G.: {loss_generator.item():.4f}\")\n","\n","train_gan(batch_size=64, num_epochs=100)\n","\n"]},{"cell_type":"markdown","source":["Let's examine the given GAN training function and locate the defects mentioned below:\n","\n","Bug Structure\n","The batch_size structural bug is activated when the value is changed to 64, among other values. Tensor sizes may not match as a result of this, especially when concatenating produced and real samples with their corresponding labels.\n","\n","The discriminator is trained with twice as many batch_size samples (generated samples plus real data) as the generator produces, which is where the problem lies. In particular, if the total number of dataset items isn't a multiple of the batch size, the batch size may change and may not match the size of the most recent batch of data loaded from the dataset.\n","\n","This is how the mistake appears:\n","\n","If the dataset size is not a multiple of 64, the final batch may not include 64 items when batch_size is adjusted to 64. This results in differing input and target sizes during the loss computation since the number of created samples (batch_size items) does not match the actual samples from the previous batch."],"metadata":{"id":"8vTmktHvKwgh"}}],"metadata":{"celltoolbar":"Create Assignment","colab":{"provenance":[{"file_id":"183DUqoHCToza4OH-PKgpkTm-d8yk_0fx","timestamp":1714752256783}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}